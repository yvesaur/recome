{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._dynamo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning_fabric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m seed_everything  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning_fabric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m disable_possible_user_warnings  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/__init__.py:14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright The Lightning AI team.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_size_finder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchSizeFinder\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Checkpoint\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/batch_size_finder.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_size_scaling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _scale_batch_size\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MisconfigurationException, _TunerExitException\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/callback.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STEP_OUTPUT\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCallback\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Abstract base class used to build new callbacks.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Subclass this class and override any of the relevant hooks\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/types.py:40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metric\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotRequired, Required\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning_fabric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _TORCH_LRSCHEDULER, LRScheduler, ProcessGroup, ReduceLROnPlateau\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchmetrics/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m _PACKAGE_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m     12\u001b[0m _PROJECT_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(_PACKAGE_ROOT)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maggregation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     CatMetric,\n\u001b[1;32m     17\u001b[0m     MaxMetric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     SumMetric,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _PermutationInvariantTraining \u001b[38;5;28;01mas\u001b[39;00m PermutationInvariantTraining  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchmetrics/functional/__init__.py:50\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     accuracy,\n\u001b[1;32m     26\u001b[0m     auroc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     stat_scores,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _panoptic_quality \u001b[38;5;28;01mas\u001b[39;00m panoptic_quality\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m     _error_relative_global_dimensionless_synthesis \u001b[38;5;28;01mas\u001b[39;00m error_relative_global_dimensionless_synthesis,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _image_gradients \u001b[38;5;28;01mas\u001b[39;00m image_gradients\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     55\u001b[0m     _multiscale_structural_similarity_index_measure \u001b[38;5;28;01mas\u001b[39;00m multiscale_structural_similarity_index_measure,\n\u001b[1;32m     56\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchmetrics/functional/image/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mergas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m error_relative_global_dimensionless_synthesis\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradients\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image_gradients\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlpips\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m learned_perceptual_image_patch_similarity\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mperceptual_path_length\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m perceptual_path_length\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpsnr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m peak_signal_noise_ratio\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchmetrics/functional/image/lpips.py:45\u001b[0m\n\u001b[1;32m     43\u001b[0m     __doctest_skip__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearned_perceptual_image_patch_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models \u001b[38;5;28;01mas\u001b[39;00m tv\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_net\u001b[39m(net: \u001b[38;5;28mstr\u001b[39m, pretrained: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mSequential:\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get torchvision network.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/convnext.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/ops/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/ops/poolers.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/ops/roi_align.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._dynamo'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from collections import Counter\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import psycopg2\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"recome\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Close the connection\n",
    "# cur.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset originally consists of 156966 number of interactions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>click_history</th>\n",
       "      <th>impressions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
       "      <td>N55689-1 N35729-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U91836</td>\n",
       "      <td>11/12/2019 6:11:30 PM</td>\n",
       "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
       "      <td>N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>U73700</td>\n",
       "      <td>11/14/2019 7:01:48 AM</td>\n",
       "      <td>N10732 N25792 N7563 N21087 N41087 N5445 N60384...</td>\n",
       "      <td>N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U34670</td>\n",
       "      <td>11/11/2019 5:28:05 AM</td>\n",
       "      <td>N45729 N2203 N871 N53880 N41375 N43142 N33013 ...</td>\n",
       "      <td>N35729-0 N33632-0 N49685-1 N27581-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>U8125</td>\n",
       "      <td>11/12/2019 4:11:21 PM</td>\n",
       "      <td>N10078 N56514 N14904 N33740</td>\n",
       "      <td>N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  userid              timestamp  \\\n",
       "0   1  U13740  11/11/2019 9:05:58 AM   \n",
       "1   2  U91836  11/12/2019 6:11:30 PM   \n",
       "2   3  U73700  11/14/2019 7:01:48 AM   \n",
       "3   4  U34670  11/11/2019 5:28:05 AM   \n",
       "4   5   U8125  11/12/2019 4:11:21 PM   \n",
       "\n",
       "                                       click_history  \\\n",
       "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
       "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
       "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
       "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
       "4                        N10078 N56514 N14904 N33740   \n",
       "\n",
       "                                         impressions  \n",
       "0                                  N55689-1 N35729-0  \n",
       "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...  \n",
       "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...  \n",
       "3                N35729-0 N33632-0 N49685-1 N27581-0  \n",
       "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute a query for behaviours\n",
    "cur.execute(\"SELECT * FROM behaviours\")\n",
    "# Fetch all the rows for news\n",
    "rows = cur.fetchall()\n",
    "column_names = [desc[0] for desc in cur.description] # Get the column names \n",
    "raw_behaviour = pd.DataFrame(rows, columns=column_names) # Create a DataFrame from the rows, with the column names\n",
    "\n",
    "print(f\"The dataset originally consists of {len(raw_behaviour)} number of interactions.\")\n",
    "raw_behaviour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The news data consist in total of 51282 number of news.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N49531</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Some Republicans inch closer to Trump impeachm...</td>\n",
       "      <td>Several Republicans grew more receptive this w...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIZARM.html</td>\n",
       "      <td>[{\"Label\": \"Mick Mulvaney\", \"Type\": \"P\", \"Wiki...</td>\n",
       "      <td>[{\"Label\": \"Mick Mulvaney\", \"Type\": \"P\", \"Wiki...</td>\n",
       "      <td>Diana Moore</td>\n",
       "      <td>April 6, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N37701</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>Russia patrolling between Turkish and Syrian f...</td>\n",
       "      <td>Battles in northern Syrian towns Tuesday were ...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIOmbO.html</td>\n",
       "      <td>[{\"Label\": \"United States\", \"Type\": \"G\", \"Wiki...</td>\n",
       "      <td>[{\"Label\": \"Turkey\", \"Type\": \"G\", \"WikidataId\"...</td>\n",
       "      <td>Henry Smith</td>\n",
       "      <td>July 5, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N11071</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Burning questions for Lions vs Packers on 'Mon...</td>\n",
       "      <td>The Green Bay Packers host the Detroit Lions f...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAILr0Y.html</td>\n",
       "      <td>[{\"Label\": \"Detroit Lions\", \"Type\": \"O\", \"Wiki...</td>\n",
       "      <td>[{\"Label\": \"Detroit Lions\", \"Type\": \"O\", \"Wiki...</td>\n",
       "      <td>Ivy Davis</td>\n",
       "      <td>July 9, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N7360</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>Just Out of Prison, Brooklyn Gunman Is Killed ...</td>\n",
       "      <td>Life for Nasheem Prioleau had become a series ...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAIQxFd.html</td>\n",
       "      <td>[{\"Label\": \"Just Out\", \"Type\": \"M\", \"WikidataI...</td>\n",
       "      <td>[{\"Label\": \"Brooklyn\", \"Type\": \"G\", \"WikidataI...</td>\n",
       "      <td>Ivy Taylor</td>\n",
       "      <td>April 22, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N11987</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>NFL power rankings, Week 8: 49ers challenging ...</td>\n",
       "      <td>With eight weeks of the 2019 NFL regular seaso...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJvUKj.html</td>\n",
       "      <td>[{\"Label\": \"New York Jets\", \"Type\": \"O\", \"Wiki...</td>\n",
       "      <td>[{\"Label\": \"New Orleans Saints\", \"Type\": \"O\", ...</td>\n",
       "      <td>Diana Taylor</td>\n",
       "      <td>September 16, 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id category   subcategory  \\\n",
       "0  N49531     news  newspolitics   \n",
       "1  N37701     news     newsworld   \n",
       "2  N11071   sports  football_nfl   \n",
       "3   N7360     news     newscrime   \n",
       "4  N11987   sports  football_nfl   \n",
       "\n",
       "                                               title  \\\n",
       "0  Some Republicans inch closer to Trump impeachm...   \n",
       "1  Russia patrolling between Turkish and Syrian f...   \n",
       "2  Burning questions for Lions vs Packers on 'Mon...   \n",
       "3  Just Out of Prison, Brooklyn Gunman Is Killed ...   \n",
       "4  NFL power rankings, Week 8: 49ers challenging ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Several Republicans grew more receptive this w...   \n",
       "1  Battles in northern Syrian towns Tuesday were ...   \n",
       "2  The Green Bay Packers host the Detroit Lions f...   \n",
       "3  Life for Nasheem Prioleau had become a series ...   \n",
       "4  With eight weeks of the 2019 NFL regular seaso...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAIZARM.html   \n",
       "1  https://assets.msn.com/labs/mind/AAIOmbO.html   \n",
       "2  https://assets.msn.com/labs/mind/AAILr0Y.html   \n",
       "3  https://assets.msn.com/labs/mind/AAIQxFd.html   \n",
       "4  https://assets.msn.com/labs/mind/AAJvUKj.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Mick Mulvaney\", \"Type\": \"P\", \"Wiki...   \n",
       "1  [{\"Label\": \"United States\", \"Type\": \"G\", \"Wiki...   \n",
       "2  [{\"Label\": \"Detroit Lions\", \"Type\": \"O\", \"Wiki...   \n",
       "3  [{\"Label\": \"Just Out\", \"Type\": \"M\", \"WikidataI...   \n",
       "4  [{\"Label\": \"New York Jets\", \"Type\": \"O\", \"Wiki...   \n",
       "\n",
       "                                   abstract_entities        author  \\\n",
       "0  [{\"Label\": \"Mick Mulvaney\", \"Type\": \"P\", \"Wiki...   Diana Moore   \n",
       "1  [{\"Label\": \"Turkey\", \"Type\": \"G\", \"WikidataId\"...   Henry Smith   \n",
       "2  [{\"Label\": \"Detroit Lions\", \"Type\": \"O\", \"Wiki...     Ivy Davis   \n",
       "3  [{\"Label\": \"Brooklyn\", \"Type\": \"G\", \"WikidataI...    Ivy Taylor   \n",
       "4  [{\"Label\": \"New Orleans Saints\", \"Type\": \"O\", ...  Diana Taylor   \n",
       "\n",
       "                 date  \n",
       "0       April 6, 2019  \n",
       "1        July 5, 2019  \n",
       "2        July 9, 2019  \n",
       "3      April 22, 2019  \n",
       "4  September 16, 2019  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute a query for news\n",
    "cur.execute(\"SELECT * FROM news1\")\n",
    "# Fetch all the rows for news\n",
    "rows = cur.fetchall()\n",
    "column_names = [desc[0] for desc in cur.description] # Get the column names \n",
    "news = pd.DataFrame(rows, columns=column_names) # Create a DataFrame from the rows, with the column names\n",
    "\n",
    "\n",
    "\n",
    "print(f\"The news data consist in total of {len(news)} number of news.\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to process the click history and impressions. We first need to decode impressions into clicks and non-clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the impressions and clicks into two seperate lists\n",
    "def process_impression(impression_list):\n",
    "    list_of_strings = impression_list.split()\n",
    "    click = [x.split('-')[0] for x in list_of_strings if x.split('-')[1] == '1']\n",
    "    non_click = [x.split('-')[0] for x in list_of_strings if x.split('-')[1] == '0']\n",
    "    return click,non_click\n",
    "\n",
    "# We can then indexize these two new columns:\n",
    "raw_behaviour['click'], raw_behaviour['noclicks'] = zip(*raw_behaviour['impressions'].map(process_impression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp value to hours since epoch\n",
    "raw_behaviour['epochhrs'] = pd.to_datetime(raw_behaviour['timestamp']).values.astype(np.int64)/(1e6)/1000/3600\n",
    "raw_behaviour['epochhrs'] = raw_behaviour['epochhrs'].round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Click History\n",
    "In the dataset we can see that a large number of items and users does not have sufficent amount of clicks. This is since we are working with a smaller version of the MIND dataset that contains 50k users instead of the full version of 1 million users. Therefore it will be hard to learn the user and item embeddings by only relying on the interactions e.g. the <b>clicks</b> and <b>noclicks</b>.\n",
    "\n",
    "To resolve this issue in the lab, we will expand the click_history column, which will add about 7 times more interactions than the original data. However, note that these events don't have any information about which articles were shown to the user e.g. the impressions or noclicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset after pre-processing consist of 1162404 number of interactions.\n"
     ]
    }
   ],
   "source": [
    "# If there exists several clicks in one session, expand to new observation\n",
    "raw_behaviour = raw_behaviour.explode(\"click\").reset_index(drop=True)\n",
    "\n",
    "# Extract the clicks from the previous clicks\n",
    "click_history = raw_behaviour[[\"userid\",\"click_history\"]].drop_duplicates().dropna()\n",
    "click_history[\"click_history\"] = click_history.click_history.map(lambda x: x.split())\n",
    "click_history = click_history.explode(\"click_history\").rename(columns={\"click_history\":\"click\"})\n",
    "\n",
    "# Dummy time set to earlies epochhrs in raw_behaviour as we don't know when these events took place.\n",
    "click_history[\"epochhrs\"] = raw_behaviour.epochhrs.min() \n",
    "click_history[\"noclicks\"] = pd.Series([[] for _ in range(len(click_history.index))])\n",
    "\n",
    "# concatenate historical clicks with the raw_behaviour\n",
    "raw_behaviour = pd.concat([raw_behaviour,click_history],axis=0).reset_index(drop=True)\n",
    "print(f\"The dataset after pre-processing consist of {len(raw_behaviour)} number of interactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold start problem\n",
    "Still after doing our pre-processing and adding the <b>click_history</b> to the <b>click column</b>, we can see that a large number of items does not have sufficent amount of clicks. This can be thought of as a <u>cold start problem</u>. To adjust for this we will remove items from the raw_behaviour that falls under the min_click_cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items that have less than 100 clicks make up 93.852 % of the total, and these will be removed.\n"
     ]
    }
   ],
   "source": [
    "min_click_cutoff = 100\n",
    "print(f'Number of items that have less than {min_click_cutoff} clicks make up',np.round(np.mean(raw_behaviour.groupby(\"click\").size() < min_click_cutoff)*100,3),'% of the total, and these will be removed.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items with less clicks than min_click_cutoff\n",
    "raw_behaviour = raw_behaviour[raw_behaviour.groupby(\"click\")[\"userid\"].transform('size') >= min_click_cutoff].reset_index(drop=True)\n",
    "# Get a set with all the unique items\n",
    "click_set = set(raw_behaviour['click'].unique())\n",
    "\n",
    "# remove items for impressions that is not avaiable in the click set (the items that we will be training on)\n",
    "raw_behaviour['noclicks'] = raw_behaviour['noclicks'].apply(lambda impressions: [impression for impression in impressions if impression in click_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Output of data preprocessing (START HERE IF YOU ARE DOING AI ACADEMY) </h2>\n",
    "In this preprocessing we have processed behaviour data, article data and user data. The main component is <b>behaviour</b>, and for collaborative filtering purposes this is all we need. However, if we want to utilize content data on the news items some additional preprocessing on the news dataframe must be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interactions in the behaviour dataset: 781873\n",
      "Number of users in the behaviour dataset: 49833\n",
      "Number of articles in the behaviour dataset: 2451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochhrs</th>\n",
       "      <th>userid</th>\n",
       "      <th>click</th>\n",
       "      <th>noclicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>437073.0</td>\n",
       "      <td>U13740</td>\n",
       "      <td>N55689</td>\n",
       "      <td>[N35729]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437106.0</td>\n",
       "      <td>U91836</td>\n",
       "      <td>N17059</td>\n",
       "      <td>[N20678, N39317, N58114, N20495, N42977, N1459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>437143.0</td>\n",
       "      <td>U73700</td>\n",
       "      <td>N23814</td>\n",
       "      <td>[N23877, N35389, N49712, N16844, N59685, N2344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>437069.0</td>\n",
       "      <td>U34670</td>\n",
       "      <td>N49685</td>\n",
       "      <td>[N35729, N33632, N27581]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>437083.0</td>\n",
       "      <td>U19739</td>\n",
       "      <td>N33619</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochhrs  userid   click                                           noclicks\n",
       "0  437073.0  U13740  N55689                                           [N35729]\n",
       "1  437106.0  U91836  N17059  [N20678, N39317, N58114, N20495, N42977, N1459...\n",
       "2  437143.0  U73700  N23814  [N23877, N35389, N49712, N16844, N59685, N2344...\n",
       "3  437069.0  U34670  N49685                           [N35729, N33632, N27581]\n",
       "4  437083.0  U19739  N33619                                                 []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select the columns that we now want to use for further analysis\n",
    "behaviour = raw_behaviour[['epochhrs','userid','click','noclicks']].copy()\n",
    "\n",
    "print('Number of interactions in the behaviour dataset:', behaviour.shape[0])\n",
    "print('Number of users in the behaviour dataset:', behaviour.userid.nunique())\n",
    "print('Number of articles in the behaviour dataset:', behaviour.click.nunique())\n",
    "\n",
    "behaviour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test Split + indexing\n",
    "Before we carry on to define our first model we first need to apply indexizing for the users and items in the behaviour dataframe, as pytorch requires integer indicies instead of strings for user and item IDs.\n",
    "\n",
    "We do this by two dictionaries:\n",
    "\n",
    "<b>ind2item </b>: mapping the item indicies given in behaviour to the real item Id given in the dataset.\n",
    "<b>ind2user</b>: mapping the user indicies given in behaviour to the real user Id given in the dataset.\n",
    "Note that we also create <b> item2ind </b> and <b> user2ind </b> to do the reverse.\n",
    "\n",
    "The indexing will be created based on the training data, where new unseen articles in the validation set will get the index 0. We will use 90% for training 10% for validation, when we split the data it's important to make use of temporal epochhrs to divide the data, as a regular random split in this case does not make sense in recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the last 10pct of the data as our validation data:\n",
    "test_time_th = behaviour['epochhrs'].quantile(0.9)\n",
    "train = behaviour[behaviour['epochhrs']< test_time_th].copy()\n",
    "\n",
    "## Indexize items\n",
    "# Allocate a unique index for each item, but let the zeroth index be a UNK index:\n",
    "ind2item = {idx +1: itemid for idx, itemid in enumerate(train.click.unique())}\n",
    "item2ind = {itemid : idx for idx, itemid in ind2item.items()}\n",
    "\n",
    "train['noclicks'] = train['noclicks'].map(lambda list_of_items: [item2ind.get(l, 0) for l in list_of_items])\n",
    "train['click'] = train['click'].map(lambda item: item2ind.get(item, 0))\n",
    "\n",
    "## Indexize users\n",
    "# Allocate a unique index for each user, but let the zeroth index be a UNK index:\n",
    "ind2user = {idx +1: userid for idx, userid in enumerate(train['userid'].unique())}\n",
    "user2ind = {userid : idx for idx, userid in ind2user.items()}\n",
    "\n",
    "# Create a new column with userIdx:\n",
    "train['userIdx'] = train['userid'].map(lambda x: user2ind.get(x,0))\n",
    "\n",
    "# Repeat for validation\n",
    "valid =  behaviour[behaviour['epochhrs']>= test_time_th].copy()\n",
    "valid[\"click\"] = valid[\"click\"].map(lambda item: item2ind.get(item, 0))\n",
    "valid[\"noclicks\"] = valid[\"noclicks\"].map(lambda list_of_items: [item2ind.get(l, 0) for l in list_of_items])\n",
    "valid[\"userIdx\"] = valid[\"userid\"].map(lambda x: user2ind.get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochhrs</th>\n",
       "      <th>userid</th>\n",
       "      <th>click</th>\n",
       "      <th>noclicks</th>\n",
       "      <th>userIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437106.0</td>\n",
       "      <td>U91836</td>\n",
       "      <td>0</td>\n",
       "      <td>[456, 326, 0, 0, 0, 477, 220, 143, 0]</td>\n",
       "      <td>7912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>437143.0</td>\n",
       "      <td>U73700</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 262, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>33857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>437110.0</td>\n",
       "      <td>U46596</td>\n",
       "      <td>0</td>\n",
       "      <td>[143, 0, 0, 0]</td>\n",
       "      <td>8708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>437122.0</td>\n",
       "      <td>U79199</td>\n",
       "      <td>0</td>\n",
       "      <td>[419, 0, 0]</td>\n",
       "      <td>13979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>437145.0</td>\n",
       "      <td>U89744</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 308, 0, 321, 0, 262, 94, 0, 103, ...</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168643</th>\n",
       "      <td>437105.0</td>\n",
       "      <td>U17467</td>\n",
       "      <td>0</td>\n",
       "      <td>[465, 147, 477, 357, 489, 143, 206, 13, 304, 4...</td>\n",
       "      <td>21122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168644</th>\n",
       "      <td>437152.0</td>\n",
       "      <td>U72015</td>\n",
       "      <td>279</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 226...</td>\n",
       "      <td>49396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168645</th>\n",
       "      <td>437127.0</td>\n",
       "      <td>U44625</td>\n",
       "      <td>0</td>\n",
       "      <td>[114, 134, 0, 0, 0, 0, 0, 357, 237, 284, 27, 1...</td>\n",
       "      <td>22123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168646</th>\n",
       "      <td>437151.0</td>\n",
       "      <td>U64800</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>6481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168647</th>\n",
       "      <td>472683.0</td>\n",
       "      <td>U1</td>\n",
       "      <td>1274</td>\n",
       "      <td>[7]</td>\n",
       "      <td>49397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79659 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        epochhrs  userid  click  \\\n",
       "1       437106.0  U91836      0   \n",
       "2       437143.0  U73700      0   \n",
       "6       437110.0  U46596      0   \n",
       "7       437122.0  U79199      0   \n",
       "9       437145.0  U89744      0   \n",
       "...          ...     ...    ...   \n",
       "168643  437105.0  U17467      0   \n",
       "168644  437152.0  U72015    279   \n",
       "168645  437127.0  U44625      0   \n",
       "168646  437151.0  U64800      0   \n",
       "168647  472683.0      U1   1274   \n",
       "\n",
       "                                                 noclicks  userIdx  \n",
       "1                   [456, 326, 0, 0, 0, 477, 220, 143, 0]     7912  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 262, 0, 0, 0, 0, 0, 0, 0...    33857  \n",
       "6                                          [143, 0, 0, 0]     8708  \n",
       "7                                             [419, 0, 0]    13979  \n",
       "9       [0, 0, 0, 0, 308, 0, 321, 0, 262, 94, 0, 103, ...      943  \n",
       "...                                                   ...      ...  \n",
       "168643  [465, 147, 477, 357, 489, 143, 206, 13, 304, 4...    21122  \n",
       "168644  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 226...    49396  \n",
       "168645  [114, 134, 0, 0, 0, 0, 0, 357, 237, 284, 27, 1...    22123  \n",
       "168646                                          [0, 0, 0]     6481  \n",
       "168647                                                [7]    49397  \n",
       "\n",
       "[79659 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling & Negative sampling\n",
    "We want to make a matrix factorization model where each user $u$ has a d-dimensional parameter vector $z_u$ and each item $i$ has a parameter vector $v_i$.\n",
    "\n",
    "Second, to simplify the computation of things and as we do not have a `noclicks` for every `click` interaction we will only utilize two **known** things in the training phase: The item the `userIdx` and `click`. However, as we want to model the binary behavior in terms of clicks and non-clicks we will make use of something called negative sampling. With negative sampling - we will draw a sample a random negative item for each known user-click combination to express  the lack of preference by the user for the sampled item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MindDataset(Dataset):\n",
    "    # A fairly simple torch dataset module that can take a pandas dataframe (as above), \n",
    "    # and convert the relevant fields into a dictionary of arrays that can be used in a dataloader\n",
    "    def __init__(self, df):\n",
    "        # Create a dictionary of tensors out of the dataframe\n",
    "        self.data = {\n",
    "            'userIdx' : torch.tensor(df.userIdx.values.astype(np.int64)),\n",
    "            'click' : torch.tensor(df.click.values.astype(np.int64))\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.data['userIdx'])\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets and dataloaders of train and validation dataframes:\n",
    "bs = 1024\n",
    "ds_train = MindDataset(train)\n",
    "train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True)\n",
    "ds_valid = MindDataset(valid)\n",
    "valid_loader = DataLoader(ds_valid, batch_size=bs, shuffle=False)\n",
    "\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "#### Framework\n",
    "We will use pytorch-lightning to define and train our model. It is a high-level framework (similar to fastAI) but with a slightly different way of defining things. It is my personal go-to framework and is very flexible. For more information, see https://pytorch-lightning.readthedocs.io/.\n",
    "\n",
    "#### The model\n",
    "We assume that each interaction goes as follow: the user is presented with two items: the click and no-click item, where the no-click item will be randomly chosen with negative sampling. After the user reviewed both items, she will choose the most relevant one. This can be modeled as a categorical distirbution with two options (yes, you could do binomial). There is a loss function in pytorch for this already, called the `F.binary_cross_entropy` that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a matrix factorization model\n",
    "class NewsMF(pl.LightningModule):\n",
    "    def __init__(self, num_users, num_items, dim = 10):\n",
    "        super().__init__()\n",
    "        self.dim=dim\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        self.useremb = nn.Embedding(num_embeddings=num_users, embedding_dim=dim)\n",
    "        self.itememb = nn.Embedding(num_embeddings=num_items, embedding_dim=dim)\n",
    "\n",
    "        \n",
    "    def step(self, batch, batch_idx, phase=\"train\"):\n",
    "        batch_size = batch['userIdx'].size(0)\n",
    "        uservec = self.useremb(batch['userIdx'])       \n",
    "        itemvec_click = self.itememb(batch['click'])\n",
    "        \n",
    "        # For each positive interaction,sample a random negative\n",
    "        neg_sample = torch.randint_like(batch[\"click\"],1,self.num_items)\n",
    "        itemvec_noclick = self.itememb(neg_sample)\n",
    "        \n",
    "        score_click = torch.sigmoid((uservec*itemvec_click).sum(-1).unsqueeze(-1))\n",
    "        score_noclick =  torch.sigmoid((uservec*itemvec_noclick).sum(-1).unsqueeze(-1))\n",
    "\n",
    "        # Compute loss as binary cross entropy (categorical distribution between the clicked and the no clicked item)\n",
    "        scores_all = torch.concat((score_click, score_noclick), dim=1)\n",
    "        target_all = torch.concat((torch.ones_like(score_click), torch.zeros_like(score_noclick)),dim=1)\n",
    "        loss = F.binary_cross_entropy(scores_all, target_all)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # for now, just do the same computation as during training\n",
    "        return self.step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/yvesito/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | useremb | Embedding | 2.5 M \n",
      "1 | itememb | Embedding | 113 K \n",
      "--------------------------------------\n",
      "2.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.335    Total estimated model params size (MB)\n",
      "/home/yvesito/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 686/686 [00:18<00:00, 36.21it/s, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 686/686 [00:19<00:00, 36.08it/s, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "# Define and train model\n",
    "mf_model = NewsMF(num_users=len(ind2user) + 1, num_items = len(ind2item) + 1, dim = 50)\n",
    "trainer = pl.Trainer(max_epochs=50, accelerator=\"gpu\")\n",
    "trainer.fit(model=mf_model, train_dataloaders=train_loader)\n",
    "\n",
    "# Save the model\n",
    "trainer.save_checkpoint(\"model_news.ckpt\")\n",
    "\n",
    "# Load the trained model\n",
    "# mf_model = NewsMF.load_from_checkpoint(checkpoint_path=\"model_news.ckpt\", num_users=len(ind2user) + 1, num_items=len(ind2item) + 1, dim = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>ind</th>\n",
       "      <th>n_click_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>N306</td>\n",
       "      <td>movies</td>\n",
       "      <td>movies-celebrity</td>\n",
       "      <td>Kevin Spacey Won't Be Charged in Sexual Assaul...</td>\n",
       "      <td>The Los Angeles County District Attorney's Off...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJy6rv.html</td>\n",
       "      <td>[{\"Label\": \"Kevin Spacey\", \"Type\": \"P\", \"Wikid...</td>\n",
       "      <td>[{\"Label\": \"Kevin Spacey\", \"Type\": \"P\", \"Wikid...</td>\n",
       "      <td>Eleanor Jones</td>\n",
       "      <td>April 27, 2019</td>\n",
       "      <td>598.0</td>\n",
       "      <td>4802.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55689</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Charles Rogers, former Michigan State football...</td>\n",
       "      <td>Charles Rogers, the former Michigan State foot...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWAPO6.html</td>\n",
       "      <td>[{\"Label\": \"Charles Rogers (American football)...</td>\n",
       "      <td>[{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...</td>\n",
       "      <td>Charlie Davis</td>\n",
       "      <td>February 9, 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>N42620</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestylebuzz</td>\n",
       "      <td>Heidi Klum's 2019 Halloween Costume Transforma...</td>\n",
       "      <td>You might say she's scary good at playing dres...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJFlhi.html</td>\n",
       "      <td>[{\"Label\": \"Heidi Klum\", \"Type\": \"P\", \"Wikidat...</td>\n",
       "      <td>[{\"Label\": \"Heidi Klum\", \"Type\": \"P\", \"Wikidat...</td>\n",
       "      <td>Grace Wilson</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>657.0</td>\n",
       "      <td>4047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>N47020</td>\n",
       "      <td>news</td>\n",
       "      <td>newsopinion</td>\n",
       "      <td>The News In Cartoons</td>\n",
       "      <td>News as seen through the eyes of the nation's ...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJ7oYd.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Charlie Davis</td>\n",
       "      <td>February 25, 2019</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N35729</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Porsche launches into second story of New Jers...</td>\n",
       "      <td>The Porsche went airborne off a median in Toms...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWyjM9.html</td>\n",
       "      <td>[{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...</td>\n",
       "      <td>[{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...</td>\n",
       "      <td>Charlie Moore</td>\n",
       "      <td>September 1, 2019</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>N40509</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>One of FBI's Most Wanted fugitives offers surr...</td>\n",
       "      <td>One of the FBI's Most Wanted fugitives says he...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWqn9T.html</td>\n",
       "      <td>[{\"Label\": \"FBI Ten Most Wanted Fugitives\", \"T...</td>\n",
       "      <td>[{\"Label\": \"FBI Ten Most Wanted Fugitives\", \"T...</td>\n",
       "      <td>Henry Williams</td>\n",
       "      <td>November 18, 2019</td>\n",
       "      <td>605.0</td>\n",
       "      <td>1014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>N54842</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>Mississippi woman found after being missing fo...</td>\n",
       "      <td>S.O.S spelled out with rocks saved a woman mis...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJvHE4.html</td>\n",
       "      <td>[{\"Label\": \"Mississippi\", \"Type\": \"G\", \"Wikida...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Grace Davis</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>772.0</td>\n",
       "      <td>1014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>N56753</td>\n",
       "      <td>news</td>\n",
       "      <td>newspolitics</td>\n",
       "      <td>Fox News contributor: 'Most likely' outcome is...</td>\n",
       "      <td>Fox News contributor Christopher Hahn predicte...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJrEwW.html</td>\n",
       "      <td>[{\"Label\": \"Donald Trump\", \"Type\": \"P\", \"Wikid...</td>\n",
       "      <td>[{\"Label\": \"Christopher Hahn\", \"Type\": \"P\", \"W...</td>\n",
       "      <td>Eleanor Williams</td>\n",
       "      <td>December 10, 2019</td>\n",
       "      <td>943.0</td>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>N4593</td>\n",
       "      <td>movies</td>\n",
       "      <td>movies-celebrity</td>\n",
       "      <td>Emily Ratajkowski Is Being Sued for $150,000 O...</td>\n",
       "      <td>What's more? The photographer is also asking f...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJga7m.html</td>\n",
       "      <td>[{\"Label\": \"Emily Ratajkowski\", \"Type\": \"P\", \"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Alice Williams</td>\n",
       "      <td>February 10, 2019</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>N32312</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>entertainment-celebrity</td>\n",
       "      <td>Kylie Jenner and her bestie get surgery togeth...</td>\n",
       "      <td>What kind of surgery did Kylie Jenner and her ...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJfSs3.html</td>\n",
       "      <td>[{\"Label\": \"Kylie Jenner\", \"Type\": \"P\", \"Wikid...</td>\n",
       "      <td>[{\"Label\": \"Kylie Jenner\", \"Type\": \"P\", \"Wikid...</td>\n",
       "      <td>Charlie Moore</td>\n",
       "      <td>November 1, 2019</td>\n",
       "      <td>833.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       category              subcategory  \\\n",
       "597     N306         movies         movies-celebrity   \n",
       "0     N55689         sports             football_nfl   \n",
       "656   N42620      lifestyle            lifestylebuzz   \n",
       "10    N47020           news              newsopinion   \n",
       "9     N35729           news                   newsus   \n",
       "...      ...            ...                      ...   \n",
       "604   N40509           news                newscrime   \n",
       "771   N54842           news                   newsus   \n",
       "942   N56753           news             newspolitics   \n",
       "1055   N4593         movies         movies-celebrity   \n",
       "832   N32312  entertainment  entertainment-celebrity   \n",
       "\n",
       "                                                  title  \\\n",
       "597   Kevin Spacey Won't Be Charged in Sexual Assaul...   \n",
       "0     Charles Rogers, former Michigan State football...   \n",
       "656   Heidi Klum's 2019 Halloween Costume Transforma...   \n",
       "10                                 The News In Cartoons   \n",
       "9     Porsche launches into second story of New Jers...   \n",
       "...                                                 ...   \n",
       "604   One of FBI's Most Wanted fugitives offers surr...   \n",
       "771   Mississippi woman found after being missing fo...   \n",
       "942   Fox News contributor: 'Most likely' outcome is...   \n",
       "1055  Emily Ratajkowski Is Being Sued for $150,000 O...   \n",
       "832   Kylie Jenner and her bestie get surgery togeth...   \n",
       "\n",
       "                                               abstract  \\\n",
       "597   The Los Angeles County District Attorney's Off...   \n",
       "0     Charles Rogers, the former Michigan State foot...   \n",
       "656   You might say she's scary good at playing dres...   \n",
       "10    News as seen through the eyes of the nation's ...   \n",
       "9     The Porsche went airborne off a median in Toms...   \n",
       "...                                                 ...   \n",
       "604   One of the FBI's Most Wanted fugitives says he...   \n",
       "771   S.O.S spelled out with rocks saved a woman mis...   \n",
       "942   Fox News contributor Christopher Hahn predicte...   \n",
       "1055  What's more? The photographer is also asking f...   \n",
       "832   What kind of surgery did Kylie Jenner and her ...   \n",
       "\n",
       "                                                url  \\\n",
       "597   https://assets.msn.com/labs/mind/AAJy6rv.html   \n",
       "0     https://assets.msn.com/labs/mind/BBWAPO6.html   \n",
       "656   https://assets.msn.com/labs/mind/AAJFlhi.html   \n",
       "10    https://assets.msn.com/labs/mind/AAJ7oYd.html   \n",
       "9     https://assets.msn.com/labs/mind/BBWyjM9.html   \n",
       "...                                             ...   \n",
       "604   https://assets.msn.com/labs/mind/BBWqn9T.html   \n",
       "771   https://assets.msn.com/labs/mind/AAJvHE4.html   \n",
       "942   https://assets.msn.com/labs/mind/AAJrEwW.html   \n",
       "1055  https://assets.msn.com/labs/mind/AAJga7m.html   \n",
       "832   https://assets.msn.com/labs/mind/AAJfSs3.html   \n",
       "\n",
       "                                         title_entities  \\\n",
       "597   [{\"Label\": \"Kevin Spacey\", \"Type\": \"P\", \"Wikid...   \n",
       "0     [{\"Label\": \"Charles Rogers (American football)...   \n",
       "656   [{\"Label\": \"Heidi Klum\", \"Type\": \"P\", \"Wikidat...   \n",
       "10                                                   []   \n",
       "9     [{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...   \n",
       "...                                                 ...   \n",
       "604   [{\"Label\": \"FBI Ten Most Wanted Fugitives\", \"T...   \n",
       "771   [{\"Label\": \"Mississippi\", \"Type\": \"G\", \"Wikida...   \n",
       "942   [{\"Label\": \"Donald Trump\", \"Type\": \"P\", \"Wikid...   \n",
       "1055  [{\"Label\": \"Emily Ratajkowski\", \"Type\": \"P\", \"...   \n",
       "832   [{\"Label\": \"Kylie Jenner\", \"Type\": \"P\", \"Wikid...   \n",
       "\n",
       "                                      abstract_entities            author  \\\n",
       "597   [{\"Label\": \"Kevin Spacey\", \"Type\": \"P\", \"Wikid...     Eleanor Jones   \n",
       "0     [{\"Label\": \"2003 NFL Draft\", \"Type\": \"U\", \"Wik...     Charlie Davis   \n",
       "656   [{\"Label\": \"Heidi Klum\", \"Type\": \"P\", \"Wikidat...      Grace Wilson   \n",
       "10                                                   []     Charlie Davis   \n",
       "9     [{\"Label\": \"Porsche\", \"Type\": \"O\", \"WikidataId...     Charlie Moore   \n",
       "...                                                 ...               ...   \n",
       "604   [{\"Label\": \"FBI Ten Most Wanted Fugitives\", \"T...    Henry Williams   \n",
       "771                                                  []       Grace Davis   \n",
       "942   [{\"Label\": \"Christopher Hahn\", \"Type\": \"P\", \"W...  Eleanor Williams   \n",
       "1055                                                 []    Alice Williams   \n",
       "832   [{\"Label\": \"Kylie Jenner\", \"Type\": \"P\", \"Wikid...     Charlie Moore   \n",
       "\n",
       "                    date     ind  n_click_training  \n",
       "597       April 27, 2019   598.0            4802.0  \n",
       "0       February 9, 2019     1.0            4316.0  \n",
       "656    September 3, 2019   657.0            4047.0  \n",
       "10     February 25, 2019    11.0            3545.0  \n",
       "9      September 1, 2019    10.0            3346.0  \n",
       "...                  ...     ...               ...  \n",
       "604    November 18, 2019   605.0            1014.0  \n",
       "771   September 21, 2019   772.0            1014.0  \n",
       "942    December 10, 2019   943.0            1008.0  \n",
       "1055   February 10, 2019  1056.0            1004.0  \n",
       "832     November 1, 2019   833.0            1001.0  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add more information to the article data \n",
    "# The item index\n",
    "news[\"ind\"] = news[\"id\"].map(item2ind)\n",
    "news = news.sort_values(\"ind\").reset_index(drop=True)\n",
    "# Number of clicks in training data per article, investigate the cold start issue\n",
    "news[\"n_click_training\"] = news[\"ind\"].map(dict(Counter(train.click)))\n",
    "# 5 most clicked articles\n",
    "# news.sort_values(\"n_click_training\",ascending=False).head()\n",
    "trendingnews = news.sort_values(\"n_click_training\",ascending=False)\n",
    "trendingnews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2279, 50])\n"
     ]
    }
   ],
   "source": [
    "# store the learned item embedding into a seperate tensor\n",
    "itememb = mf_model.itememb.weight.detach()\n",
    "print(itememb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>ind</th>\n",
       "      <th>n_click_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>N55582</td>\n",
       "      <td>movies</td>\n",
       "      <td>movies-celebrity</td>\n",
       "      <td>Halle Berry, 53, flaunts chiseled abs on Insta...</td>\n",
       "      <td>Halle Berry is trying to motivate her social m...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWtN08.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Jack Williams</td>\n",
       "      <td>June 13, 2019</td>\n",
       "      <td>30.0</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N24272</td>\n",
       "      <td>movies</td>\n",
       "      <td>movies-celebrity</td>\n",
       "      <td>Actress Accuses Roman Polanski of Raping Her i...</td>\n",
       "      <td>'Devil Fish' actor Valentine Monnier accuses t...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/BBWu461.html</td>\n",
       "      <td>[{\"Label\": \"Roman Polanski\", \"Type\": \"P\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Le Parisien\", \"Type\": \"M\", \"Wikida...</td>\n",
       "      <td>Ivy Johnson</td>\n",
       "      <td>October 10, 2019</td>\n",
       "      <td>32.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id category       subcategory  \\\n",
       "29  N55582   movies  movies-celebrity   \n",
       "31  N24272   movies  movies-celebrity   \n",
       "\n",
       "                                                title  \\\n",
       "29  Halle Berry, 53, flaunts chiseled abs on Insta...   \n",
       "31  Actress Accuses Roman Polanski of Raping Her i...   \n",
       "\n",
       "                                             abstract  \\\n",
       "29  Halle Berry is trying to motivate her social m...   \n",
       "31  'Devil Fish' actor Valentine Monnier accuses t...   \n",
       "\n",
       "                                              url  \\\n",
       "29  https://assets.msn.com/labs/mind/BBWtN08.html   \n",
       "31  https://assets.msn.com/labs/mind/BBWu461.html   \n",
       "\n",
       "                                       title_entities  \\\n",
       "29                                                 []   \n",
       "31  [{\"Label\": \"Roman Polanski\", \"Type\": \"P\", \"Wik...   \n",
       "\n",
       "                                    abstract_entities         author  \\\n",
       "29                                                 []  Jack Williams   \n",
       "31  [{\"Label\": \"Le Parisien\", \"Type\": \"M\", \"Wikida...    Ivy Johnson   \n",
       "\n",
       "                date   ind  n_click_training  \n",
       "29     June 13, 2019  30.0             393.0  \n",
       "31  October 10, 2019  32.0             509.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate different rows of the item embedding (articles embeddings) to see if the model works\n",
    "## some examples N13259, N16636, N10272\n",
    "## Can you find some examples that does not work good? Why?\n",
    "\n",
    "ind = item2ind.get(\"N10272\") \n",
    "SelectedNews = news[news['id'] == \"N306\"].category.values[0]\n",
    "print(SelectedNews)\n",
    "# This calculates the cosine similarity and outputs the 10 most similar articles w.r.t to ind in descending order\n",
    "similarity = torch.nn.functional.cosine_similarity( itememb[ind], itememb, dim=0)\n",
    "# y_true = similarity.argsort(descending=False)-1\n",
    "# print(similarity)\n",
    "# print(y_true)\n",
    "most_sim = news[~news.ind.isna()].iloc[( similarity.argsort(descending=True).numpy()-1)]\n",
    "\n",
    "most_sim = most_sim[most_sim['category'] == SelectedNews]\n",
    "most_sim.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
